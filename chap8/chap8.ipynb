{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8章 ディープラーニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ディープラーニングは、層を深くしたディープなニューラルネットワークです。こ れまで説明してきたネットワークをベースに、後は層を重ねるだけで、ディープな ネットワークを作ることができます。しかし、ディープなネットワークには課題もあ ります。本章では、ディープラーニングの性質と課題、そして可能性について見てい きます。また、現在のディープラーニングについて俯瞰した説明を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1.2 さらに認識精度を高めるには"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先のランキングの上位の手法を参考にすると、認識精度をさらに高めるための技 術やヒントを発見できるでしょう。たとえば、アンサンブル学習、学習係数の減衰 (learning rate decay)、Data Augmentation(データ拡張)などは、認識精度の向上 に貢献していることが分かります。特に、Data Augmentation は簡単な手法であり\n",
    "ながら、認識精度を向上させる上で特に有効な方法です。\n",
    "Data Augmentation は、入力画像(訓練画像)をアルゴリズムによって“人工的”\n",
    "に拡張します。具体的に言うと、図8-4 に示すように、入力画像に対して、回転や縦 横方向の移動などの微小な変化を与え、画像枚数を増やすことを行います。これは、 データセットの枚数が限られている場合には特に有効な手段です。<br>\n",
    "<img src='./fig/スクリーンショット 2022-09-26 21.17.11.png'> <br>\n",
    "Data Augmentation は、図8-4 のような変形以外にも、さまざまな方法で画像を 拡張することができます。たとえば、画像の中から一部を切り出す「crop 処理」や、 左右をひっくり返す「flip 処理†2」などです。また、一般的な画像では、輝度などの見た目の変化や拡大・縮小などのスケール変化をつけることも有効です。いずれにせ よ、Data Augmentation によって訓練画像をうまく増やすことができれば、ディー プラーニングの認識精度を向上させることができます。これは簡単な“トリック”に 思えるかもしれませんが、良い結果をもたらすことが多くあります。ここでは Data Augmentation の実装は行いませんが、この“トリック”の実装は簡単に行えますの で、興味のある方は試してみてください。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1.3 層を深くすることのモチベーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「層を深くすること」の重要性については、理論的にはそれほど多くのことが分かっ ていないのが現状です。理論的側面は現在のところ乏しいにしろ、これまでの研究や 実験から、説明できることはいくつかあります(やや直感的にではあるにせよ)。こ こでは、「層を深くすること」の重要性について、それを補強するデータや説明をい くつか与えたいと思います。\n",
    "まず初めに、層を深くすることの重要性は、ILSVRC に代表される大規模画像認 識のコンペティションの結果から汲み取ることができます(詳細は次節を参照)。そ のようなコンペティションの結果が示すところでは、最近の上位を占める手法の多く はディープラーニングによる手法であり、傾向としては、ネットワークの層を深くす る方向へ向かっています。つまり、層を深くすることに比例して、認識性能も向上し ていると読み取れます。\n",
    "続いて、層を深くすることの利点について述べます。層を深くすることの利点のひ とつは、ネットワークのパラメータ数を少なくできることです。より詳しく言えば、 層を深くしたネットワークは、層を深くしなかった場合に比べて、より少ないパラ メータで同レベル(もしくはそれ以上)の表現力を達成できるのです。このことは、 畳み込み演算でのフィルターサイズに着目して考えてみると分かりやすいでしょう。 たとえば、5 × 5 のフィルターからなる畳み込み層の例を図8-5 に示します。\n",
    "ここで注目してほしい点は、出力データの各ノードは、入力データのどの領域から 計算されているか、ということです。当たり前ですが、図8-5 の例では、出力ノード ひとつあたり、入力データの 5 × 5 の領域から計算されることになります。続いて、 図8-6 のように、3 × 3 の畳み込み演算を 2 回繰り返して行う場合を考えます。この 場合、出力ノードひとつあたり、中間データでは 3 × 3 の領域から計算されます。そ れでは、中間データの 3 × 3 の領域は、ひとつ前の入力データのどの領域から計算さ れるでしょうか? 図8-6 をよく見て考えれば、それは 5 × 5 の領域に対応すること が分かります。つまり、図8-6 の出力データは、入力データの 5 × 5 の領域を“見 て”計算することになるのです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./fig/スクリーンショット 2022-09-26 22.28.54.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
